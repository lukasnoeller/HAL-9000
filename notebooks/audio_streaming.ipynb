{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2df6c65c-4f70-47ea-9ede-c3ad1db77cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from langchain_community.utilities.nvidia_riva import AudioStream\n",
    "import pywav \n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "998a9d24-a737-4049-bdbf-c2af365807f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = \"slum.wav\"\n",
    "wav_file = pywav.WavRead(audio_file)\n",
    "audio_data = wav_file.getdata()\n",
    "sample_rate = wav_file.getsamplerate()\n",
    "delay_time = 1 / 4\n",
    "chunk_size = int(sample_rate * delay_time)\n",
    "delay_time = 1 / 8\n",
    "num_channels = wav_file.getnumofchannels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a2a2aaf1-96c3-4948-8016-477ea74675a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 73\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m producer_task\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m consumer_task\n",
      "Cell \u001b[0;32mIn[44], line 39\u001b[0m, in \u001b[0;36mconsumer\u001b[0;34m(input_stream, output_stream)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03mConsumes audio chunks from input stream and passes them along the chain\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03mconstructed comprised of ASR -> text based prompt for an LLM -> TTS chunks\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03mwith synthesized voice of LLM response put in an output stream.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m input_stream\u001b[38;5;241m.\u001b[39mcomplete:\n\u001b[0;32m---> 39\u001b[0m      \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m input_stream:\n\u001b[1;32m     40\u001b[0m    \u001b[38;5;66;03m# async for chunk in chain.astream(input_stream):\u001b[39;00m\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m output_stream\u001b[38;5;241m.\u001b[39mput(\n\u001b[1;32m     42\u001b[0m             chunk\n\u001b[1;32m     43\u001b[0m         )\n",
      "File \u001b[0;32m~/Development/voice_assistant/.venv/lib/python3.10/site-packages/langchain_community/utilities/nvidia_riva.py:306\u001b[0m, in \u001b[0;36mAudioStream.__aiter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# hangup when requested\u001b[39;00m\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m next_val \u001b[38;5;241m==\u001b[39m HANGUP:\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# yield next item\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "def chunk_audio(audio_array, n):\n",
    "    chunk_size = len(audio_array) // n\n",
    "    return [audio_array[i * chunk_size : (i + 1) * chunk_size] for i in range(n)]\n",
    "\n",
    "# Step 1: Load WAV file\n",
    "with wave.open(audio_file, \"rb\") as wf:\n",
    "    channels = wf.getnchannels()\n",
    "    sample_width = wf.getsampwidth()\n",
    "    framerate = wf.getframerate()\n",
    "    total_frames = wf.getnframes()\n",
    "    audio_bytes = wf.readframes(total_frames)\n",
    "\n",
    "# Step 2: Convert to NumPy array\n",
    "dtype_map = {1: np.int8, 2: np.int16, 4: np.int32}\n",
    "dtype = dtype_map[sample_width]\n",
    "\n",
    "audio_array = np.frombuffer(audio_bytes, dtype=dtype)\n",
    "    \n",
    "# audio_chunks = [\n",
    "#     audio_data[0 + i : chunk_size + i] for i in range(0, len(audio_data), chunk_size)\n",
    "# ]\n",
    "\n",
    "audio_chunks = chunk_audio(audio_array, 8)\n",
    "\n",
    "async def producer(input_stream) -> None:\n",
    "    \"\"\"Produces audio chunk bytes into an AudioStream as streaming audio input.\"\"\"\n",
    "    for chunk in audio_chunks:\n",
    "        await input_stream.aput(chunk)\n",
    "    input_stream.close()\n",
    "\n",
    "\n",
    "async def consumer(input_stream, output_stream) -> None:\n",
    "    \"\"\"\n",
    "    Consumes audio chunks from input stream and passes them along the chain\n",
    "    constructed comprised of ASR -> text based prompt for an LLM -> TTS chunks\n",
    "    with synthesized voice of LLM response put in an output stream.\n",
    "    \"\"\"\n",
    "    while not input_stream.complete:\n",
    "         async for chunk in input_stream:\n",
    "       # async for chunk in chain.astream(input_stream):\n",
    "            await output_stream.put(\n",
    "                chunk\n",
    "            )  # for production code don't forget to add a timeout\n",
    "\n",
    "\n",
    "input_stream = AudioStream(maxsize=1000)\n",
    "output_stream = asyncio.Queue()\n",
    "\n",
    "# send data into the chain\n",
    "producer_task = asyncio.create_task(producer(input_stream))\n",
    "# get data out of the chain\n",
    "consumer_task = asyncio.create_task(consumer(input_stream, output_stream))\n",
    "gen_audio_last = 0\n",
    "while not consumer_task.done():\n",
    "    try:\n",
    "\n",
    "        generated_audio = await asyncio.wait_for(\n",
    "            output_stream.get(), timeout=2\n",
    "        )  # for production code don't forget to add a timeout\n",
    "            \n",
    "        if generated_audio != gen_audio_last:\n",
    "            gen_audio_last = generated_audio\n",
    "            sd.play(generated_audio, samplerate=framerate)\n",
    "            # audio_array = np.frombuffer(generated_audio, dtype=np.int16)\n",
    "            # #audio_array = np.frombuffer(generated_audio, dtype=np.int16)\n",
    "            # sd.play(audio_array, samplerate=sample_rate)\n",
    "        #sd.play(generated_audio, samplerate=sample_rate)\n",
    "\n",
    "    except asyncio.TimeoutError:\n",
    "        continue\n",
    "\n",
    "await producer_task\n",
    "await consumer_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "156f671f-9d49-4212-8d47-f6b66e2827b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "file does not start with RIFF id",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m chunk_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4096\u001b[39m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Step 1: Load WAV file\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mwave\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m wf:\n\u001b[1;32m      8\u001b[0m     channels \u001b[38;5;241m=\u001b[39m wf\u001b[38;5;241m.\u001b[39mgetnchannels()\n\u001b[1;32m      9\u001b[0m     sample_width \u001b[38;5;241m=\u001b[39m wf\u001b[38;5;241m.\u001b[39mgetsampwidth()\n",
      "File \u001b[0;32m/usr/lib/python3.10/wave.py:509\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(f, mode)\u001b[0m\n\u001b[1;32m    507\u001b[0m         mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mWave_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Wave_write(f)\n",
      "File \u001b[0;32m/usr/lib/python3.10/wave.py:163\u001b[0m, in \u001b[0;36mWave_read.__init__\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# else, assume it is an open file object already\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitfp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_i_opened_the_file:\n",
      "File \u001b[0;32m/usr/lib/python3.10/wave.py:130\u001b[0m, in \u001b[0;36mWave_read.initfp\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m Chunk(file, bigendian \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mgetname() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRIFF\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Error(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile does not start with RIFF id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m4\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWAVE\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Error(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot a WAVE file\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mError\u001b[0m: file does not start with RIFF id"
     ]
    }
   ],
   "source": [
    "# Load audio from file\n",
    "\n",
    "audio_file = \"slum.wav\"\n",
    "chunk_size = 4096 \n",
    "\n",
    "# Step 1: Load WAV file\n",
    "with wave.open(audio_file, \"rb\") as wf:\n",
    "    channels = wf.getnchannels()\n",
    "    sample_width = wf.getsampwidth()\n",
    "    print(f\"Sample width: {sample_width}\")\n",
    "    framerate = wf.getframerate()\n",
    "    total_frames = wf.getnframes()\n",
    "    audio_bytes = wf.readframes(total_frames)\n",
    "\n",
    "audio_chunks = [\n",
    "    audio_bytes[i : i + chunk_size]\n",
    "    for i in range(0, len(audio_bytes), chunk_size)\n",
    "]\n",
    "\n",
    "\n",
    "with sd.OutputStream(samplerate=16000, channels=1, dtype='int16') as stream:\n",
    "    for chunk in audio_chunks:\n",
    "        audio_np = np.frombuffer(chunk, dtype=np.int16)  # if 16-bit mono PCM\n",
    "        #sd.play(audio_np, samplerate=framerate)\n",
    "        stream.write(audio_np)\n",
    "\n",
    "            \n",
    "    #sd.wait()\n",
    "# raw_audio = b\"\".join(audio_chunks)\n",
    "# audio_np = np.frombuffer(raw_audio, dtype=np.int16)\n",
    "# sd.play(audio_np, samplerate=framerate)\n",
    "# sd.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b5da1606-9a26-4f8f-9bfc-b7b4d71ce75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "from ttstokenizer import TTSTokenizer\n",
    "\n",
    "tokenizer = TTSTokenizer()\n",
    "print(len(tokenizer(\"Text to tokenize\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35600c1a-3529-46c9-9e85-6698c1d29fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
